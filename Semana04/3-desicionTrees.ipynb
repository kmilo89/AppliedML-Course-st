{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de Decisión (Decision Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- División recursiva: El árbol divide el espacio de entrada en regiones basadas en reglas.\n",
    "- Impureza: Cómo se decide la mejor división (Gini, entropía para clasificación; varianza para regresión).\n",
    "- Sobreajuste: Árboles sin poda tienden a sobreajustar.\n",
    "- Profundidad del árbol: Hiperparámetro clave para controlar la complejidad.\n",
    "- Visualización de reglas: Cada nodo representa una pregunta; las hojas, decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar un dataset sintético\n",
    "Datos artificiales que simulan problemas de clasificación.\n",
    "\n",
    "- n_samples=200: Genera 200 ejemplos o filas (puntos de datos).\n",
    "- n_features=2:Cada ejemplo tiene 2 características (columnas), es decir, X.shape = (200, 2).\n",
    "- n_informative=2: Las 2 características realmente contienen información útil para separar las clases.\n",
    "- n_redundant=0: No se incluyen características redundantes (combinaciones lineales de las informativas).\n",
    "- n_clusters_per_class=1: Cada clase se genera a partir de 1 grupo o clúster (simplifica la visualización).\n",
    "- random_state=42: Semilla para que el resultado sea reproducible (siempre se generan los mismos datos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar 200 muestras de 2 caracteristicas, ambas información útil, no redundante, con 1 cluster por clase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar grafica de dispersión \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establecer el Pipeline de estandarización y clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar el árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plot_tree(pipe.named_steps['decisionTree'], feature_names=['X1', 'X2'], class_names=['Clase 0', 'Clase 1'], filled=True)\n",
    "plt.title(\"Árbol de decisión (clasificación)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = pipe.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.4)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, edgecolor='k')\n",
    "plt.title(\"Frontera de decisión k-NN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "- Cambiar la profundidad del árbol y observar el efecto sobre la frontera.\n",
    "- Usar 'entropy' en lugar de 'gini' como criterio.\n",
    "- Aplicar el modelo al dataset wine o breast_cancer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
